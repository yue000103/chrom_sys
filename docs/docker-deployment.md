# æ¶²ç›¸è‰²è°±ä»ªç³»ç»Ÿ Docker éƒ¨ç½²æ–¹æ¡ˆ

## ğŸ³ æ–¹æ¡ˆæ¦‚è¿°

åŸºäºDockerå®¹å™¨åŒ–éƒ¨ç½²ï¼Œæœ€å°åŒ–å¯¹æ ‘è“æ´¾ç³»ç»Ÿçš„ä¿®æ”¹ï¼Œæä¾›ç®€å•ã€å¯é ã€æ˜“ç»´æŠ¤çš„éƒ¨ç½²æ–¹æ¡ˆã€‚

### æ ¸å¿ƒä¼˜åŠ¿
- **æœ€å°åŒ–ç³»ç»Ÿä¿®æ”¹**: åªéœ€å®‰è£…Dockerï¼Œæ— éœ€å¤æ‚é…ç½®
- **ç¯å¢ƒéš”ç¦»**: åº”ç”¨è¿è¡Œåœ¨å®¹å™¨ä¸­ï¼Œä¸æ±¡æŸ“å®¿ä¸»ç³»ç»Ÿ
- **ä¸€é”®éƒ¨ç½²**: `docker-compose up -d` å³å¯å¯åŠ¨
- **æ˜“äºç»´æŠ¤**: å®¹å™¨åŒ–ç®¡ç†ï¼Œæ›´æ–°é‡å¯ç®€å•
- **è·¨å¹³å°**: å¯åœ¨ä»»ä½•æ”¯æŒDockerçš„ARM64è®¾å¤‡è¿è¡Œ

## ğŸ“¦ å®¹å™¨æ¶æ„è®¾è®¡

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     æ ‘è“æ´¾å®¿ä¸»æœº                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚   Frontend      â”‚  â”‚    Backend      â”‚  â”‚     Redis     â”‚ â”‚
â”‚  â”‚  (Nginx+Vue)    â”‚  â”‚ (FastAPI+SQLite)â”‚  â”‚  (ç¼“å­˜/é˜Ÿåˆ—)   â”‚ â”‚
â”‚  â”‚  Port: 80       â”‚  â”‚  Port: 8008     â”‚  â”‚ Port: 6379    â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚           â”‚                     â”‚                     â”‚      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                   â”‚
â”‚  â”‚   SQLite DB     â”‚  â”‚     MQTT        â”‚                   â”‚
â”‚  â”‚  (æœ¬åœ°æ–‡ä»¶)      â”‚  â”‚   (æ¶ˆæ¯é˜Ÿåˆ—)     â”‚                   â”‚
â”‚  â”‚  æŒä¹…åŒ–å­˜å‚¨      â”‚  â”‚  å¤–éƒ¨broker     â”‚                   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â”‚
â”‚                                                             â”‚
â”‚  è®¾å¤‡è®¿é—®: /dev/ttyAMA* â†’ Backendå®¹å™¨ (privileged)           â”‚
â”‚  ç½‘ç»œè®¾å¤‡: Hostç½‘ç»œæ¨¡å¼                                      â”‚
â”‚  æ•°æ®åº“: SQLiteæ–‡ä»¶æ˜ å°„åˆ°å®¿ä¸»æœº                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸš€ å¿«é€Ÿéƒ¨ç½²æŒ‡å—

### 1. ç³»ç»Ÿè¦æ±‚

#### æœ€å°é…ç½®
- **ç¡¬ä»¶**: æ ‘è“æ´¾3B+ (1GB RAM)
- **å­˜å‚¨**: 32GB MicroSDå¡
- **ç³»ç»Ÿ**: Raspberry Pi OS Lite (64-bit)
- **Docker**: 20.10+

#### æ¨èé…ç½®
- **ç¡¬ä»¶**: æ ‘è“æ´¾4B (4GB/8GB RAM)
- **å­˜å‚¨**: 64GB+ MicroSDå¡æˆ–SSD
- **ç³»ç»Ÿ**: Raspberry Pi OS Lite (64-bit)
- **ç½‘ç»œ**: åƒå…†ç½‘å¡ + WiFi

### 2. å®‰è£…Docker

```bash
# æ›´æ–°ç³»ç»Ÿ
sudo apt update && sudo apt upgrade -y

# å®‰è£…Docker
curl -fsSL https://get.docker.com -o get-docker.sh
sudo sh get-docker.sh

# æ·»åŠ ç”¨æˆ·åˆ°dockerç»„
sudo usermod -aG docker $USER

# å®‰è£…Docker Compose
sudo apt install docker-compose-plugin -y

# éªŒè¯å®‰è£…
docker --version
docker compose version

# é‡å¯åº”ç”¨ç”¨æˆ·ç»„æƒé™
newgrp docker
```

### 3. ç³»ç»Ÿé…ç½®ï¼ˆæœ€å°åŒ–ä¿®æ”¹ï¼‰

```bash
# å¯ç”¨ä¸²å£ï¼ˆå”¯ä¸€éœ€è¦çš„ç³»ç»Ÿä¿®æ”¹ï¼‰
sudo raspi-config
# Interface Options â†’ Serial Port â†’ No (login shell) â†’ Yes (hardware enabled)

# æ·»åŠ ä¸²å£é…ç½®åˆ° /boot/config.txt
echo 'enable_uart=1' | sudo tee -a /boot/config.txt

# é‡å¯åº”ç”¨é…ç½®
sudo reboot
```

## ğŸ“ é¡¹ç›®æ–‡ä»¶ç»“æ„

åˆ›å»ºä»¥ä¸‹Dockeréƒ¨ç½²æ–‡ä»¶ï¼š

### 1. docker-compose.yml

```yaml
version: '3.8'

services:
  # Redis ç¼“å­˜
  redis:
    image: redis:7-alpine
    container_name: chromatography-redis
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5

  # FastAPI åç«¯ (ä½¿ç”¨SQLite)
  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile
    container_name: chromatography-backend
    environment:
      - DATABASE_URL=sqlite:///app/data/chromatography.db
      - REDIS_URL=redis://redis:6379/0
      - MQTT_BROKER=${MQTT_BROKER:-broker.emqx.io}
      - MQTT_PORT=${MQTT_PORT:-1883}
    ports:
      - "8008:8008"
    volumes:
      - ./backend:/app
      - ./data/logs:/app/logs
      - ./data/database:/app/data  # SQLiteæ•°æ®åº“æ–‡ä»¶ç›®å½•
    devices:
      - /dev/ttyAMA0:/dev/ttyAMA0  # å‹åŠ›ä¼ æ„Ÿå™¨
      - /dev/ttyAMA1:/dev/ttyAMA1
      - /dev/ttyAMA2:/dev/ttyAMA2  # æ³µæ§åˆ¶å™¨
      - /dev/ttyAMA3:/dev/ttyAMA3  # æ£€æµ‹å™¨
    privileged: true  # è®¿é—®ä¸²å£è®¾å¤‡éœ€è¦ç‰¹æƒæ¨¡å¼
    network_mode: host  # ä½¿ç”¨ä¸»æœºç½‘ç»œè®¿é—®IPè®¾å¤‡
    depends_on:
      redis:
        condition: service_healthy
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8008/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Vue å‰ç«¯
  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
    container_name: chromatography-frontend
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./docker/nginx.conf:/etc/nginx/nginx.conf:ro
    depends_on:
      - backend
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost"]
      interval: 30s
      timeout: 10s
      retries: 3

volumes:
  redis_data:

networks:
  default:
    name: chromatography-network
```

### 2. åç«¯Dockerfile

```dockerfile
# backend/Dockerfile
FROM python:3.11-slim-bookworm

# å®‰è£…ç³»ç»Ÿä¾èµ–
RUN apt-get update && apt-get install -y \
    curl \
    build-essential \
    && rm -rf /var/lib/apt/lists/*

# è®¾ç½®å·¥ä½œç›®å½•
WORKDIR /app

# å¤åˆ¶requirementsæ–‡ä»¶
COPY requirements.txt .

# å®‰è£…Pythonä¾èµ–
RUN pip install --no-cache-dir -r requirements.txt

# å¤åˆ¶åº”ç”¨ä»£ç 
COPY . .

# åˆ›å»ºå¿…è¦ç›®å½•
RUN mkdir -p /app/logs /app/data

# æš´éœ²ç«¯å£
EXPOSE 8008

# å¥åº·æ£€æŸ¥
HEALTHCHECK --interval=30s --timeout=10s --start-period=5s --retries=3 \
    CMD curl -f http://localhost:8008/health || exit 1

# å¯åŠ¨å‘½ä»¤
CMD ["python", "-m", "uvicorn", "main:app", "--host", "0.0.0.0", "--port", "8008", "--reload"]
```

### 3. å‰ç«¯Dockerfile

```dockerfile
# frontend/Dockerfile
# æ„å»ºé˜¶æ®µ
FROM node:18-alpine AS builder

WORKDIR /app

# å¤åˆ¶packageæ–‡ä»¶
COPY package*.json ./

# å®‰è£…ä¾èµ–
RUN npm ci --only=production

# å¤åˆ¶æºä»£ç 
COPY . .

# æ„å»ºç”Ÿäº§ç‰ˆæœ¬
RUN npm run build

# ç”Ÿäº§é˜¶æ®µ
FROM nginx:alpine

# å¤åˆ¶æ„å»ºç»“æœ
COPY --from=builder /app/dist /usr/share/nginx/html

# å¤åˆ¶nginxé…ç½®
COPY docker/nginx.conf /etc/nginx/nginx.conf

# æš´éœ²ç«¯å£
EXPOSE 80 443

# å¯åŠ¨nginx
CMD ["nginx", "-g", "daemon off;"]
```

### 4. Nginxé…ç½®

```nginx
# docker/nginx.conf
events {
    worker_connections 1024;
}

http {
    include /etc/nginx/mime.types;
    default_type application/octet-stream;

    # æ—¥å¿—é…ç½®
    log_format main '$remote_addr - $remote_user [$time_local] "$request" '
                    '$status $body_bytes_sent "$http_referer" '
                    '"$http_user_agent" "$http_x_forwarded_for"';

    access_log /var/log/nginx/access.log main;
    error_log /var/log/nginx/error.log;

    # åŸºæœ¬é…ç½®
    sendfile on;
    tcp_nopush on;
    tcp_nodelay on;
    keepalive_timeout 65;
    types_hash_max_size 2048;

    # Gzipå‹ç¼©
    gzip on;
    gzip_vary on;
    gzip_min_length 10240;
    gzip_proxied expired no-cache no-store private must-revalidate;
    gzip_types text/plain text/css text/xml text/javascript
               application/x-javascript application/xml+rss
               application/javascript application/json;

    server {
        listen 80;
        server_name _;
        root /usr/share/nginx/html;
        index index.html index.htm;

        # å‰ç«¯é™æ€æ–‡ä»¶
        location / {
            try_files $uri $uri/ /index.html;

            # ç¼“å­˜é™æ€èµ„æº
            location ~* \.(js|css|png|jpg|jpeg|gif|ico|svg)$ {
                expires 1y;
                add_header Cache-Control "public, immutable";
            }
        }

        # APIä»£ç†åˆ°åç«¯
        location /api/ {
            proxy_pass http://chromatography-backend:8008;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;

            # è¶…æ—¶è®¾ç½®
            proxy_connect_timeout 60s;
            proxy_send_timeout 60s;
            proxy_read_timeout 60s;
        }

        # WebSocketæ”¯æŒ
        location /ws/ {
            proxy_pass http://chromatography-backend:8008;
            proxy_http_version 1.1;
            proxy_set_header Upgrade $http_upgrade;
            proxy_set_header Connection "upgrade";
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
        }

        # å¥åº·æ£€æŸ¥
        location /health {
            access_log off;
            return 200 "healthy\n";
            add_header Content-Type text/plain;
        }
    }
}
```

### 5. ç¯å¢ƒå˜é‡é…ç½®

```bash
# .env
# æ•°æ®åº“é…ç½® (SQLite - æ— éœ€ç”¨æˆ·åå¯†ç )
DATABASE_URL=sqlite:///app/data/chromatography.db

# MQTTé…ç½®
MQTT_BROKER=broker.emqx.io
MQTT_PORT=1883
MQTT_USERNAME=
MQTT_PASSWORD=

# åº”ç”¨é…ç½®
APP_ENV=production
DEBUG=false
LOG_LEVEL=INFO

# å®‰å…¨é…ç½®
SECRET_KEY=your_secret_key_here
JWT_SECRET=your_jwt_secret_here
```

### 6. SQLiteæ•°æ®åº“åˆå§‹åŒ–è„šæœ¬

```python
# backend/init_database.py
import sqlite3
import os
from datetime import datetime

def init_sqlite_database(db_path="/app/data/chromatography.db"):
    """åˆå§‹åŒ–SQLiteæ•°æ®åº“"""

    # ç¡®ä¿ç›®å½•å­˜åœ¨
    os.makedirs(os.path.dirname(db_path), exist_ok=True)

    # è¿æ¥æ•°æ®åº“ï¼ˆä¸å­˜åœ¨ä¼šè‡ªåŠ¨åˆ›å»ºï¼‰
    conn = sqlite3.connect(db_path)
    cursor = conn.cursor()

    # è®¾å¤‡æ•°æ®è¡¨
    cursor.execute("""
        CREATE TABLE IF NOT EXISTS device_data (
            id TEXT PRIMARY KEY DEFAULT (lower(hex(randomblob(16)))),
            device_id VARCHAR(50) NOT NULL,
            device_type VARCHAR(20) NOT NULL,
            value REAL NOT NULL,
            timestamp DATETIME DEFAULT CURRENT_TIMESTAMP,
            status VARCHAR(20) DEFAULT 'normal'
        )
    """)

    # åˆ›å»ºç´¢å¼•
    cursor.execute("CREATE INDEX IF NOT EXISTS idx_device_data_timestamp ON device_data(timestamp)")
    cursor.execute("CREATE INDEX IF NOT EXISTS idx_device_data_device_id ON device_data(device_id)")

    # MQTTæ¶ˆæ¯æ—¥å¿—è¡¨
    cursor.execute("""
        CREATE TABLE IF NOT EXISTS mqtt_messages (
            id TEXT PRIMARY KEY DEFAULT (lower(hex(randomblob(16)))),
            topic VARCHAR(255) NOT NULL,
            payload TEXT,
            qos INTEGER DEFAULT 0,
            timestamp DATETIME DEFAULT CURRENT_TIMESTAMP
        )
    """)

    # ç³»ç»Ÿæ—¥å¿—è¡¨
    cursor.execute("""
        CREATE TABLE IF NOT EXISTS system_logs (
            id TEXT PRIMARY KEY DEFAULT (lower(hex(randomblob(16)))),
            level VARCHAR(10) NOT NULL,
            message TEXT NOT NULL,
            module VARCHAR(50),
            timestamp DATETIME DEFAULT CURRENT_TIMESTAMP
        )
    """)

    # æ’å…¥åˆå§‹æ•°æ®
    cursor.execute("""
        INSERT OR IGNORE INTO device_data (device_id, device_type, value) VALUES
        ('pressure_sensor_1', 'pressure', 0.0),
        ('detector_1', 'detector', 0.0),
        ('pump_1', 'pump', 0.0)
    """)

    # æäº¤æ›´æ”¹
    conn.commit()
    conn.close()

    print(f"SQLiteæ•°æ®åº“åˆå§‹åŒ–å®Œæˆ: {db_path}")

if __name__ == "__main__":
    init_sqlite_database()
```

```bash
# åœ¨Dockerfileä¸­æ·»åŠ åˆå§‹åŒ–å‘½ä»¤
# ä¿®æ”¹backend/Dockerfileï¼Œåœ¨å¯åŠ¨å‘½ä»¤å‰æ·»åŠ ï¼š
RUN python init_database.py
```

## ğŸš€ éƒ¨ç½²å‘½ä»¤

### 1. ä¸€é”®éƒ¨ç½²

```bash
# å…‹éš†ä»£ç åˆ°æ ‘è“æ´¾
git clone <your-repo-url> /opt/chromatography
cd /opt/chromatography

# å¤åˆ¶ç¯å¢ƒå˜é‡æ–‡ä»¶
cp .env.example .env
# ç¼–è¾‘ .env æ–‡ä»¶è®¾ç½®MQTTç­‰é…ç½®ï¼ˆSQLiteæ— éœ€å¯†ç ï¼‰

# åˆ›å»ºæ•°æ®ç›®å½•
mkdir -p data/database data/logs

# æ„å»ºå¹¶å¯åŠ¨æ‰€æœ‰æœåŠ¡
docker compose up -d

# æŸ¥çœ‹æœåŠ¡çŠ¶æ€
docker compose ps
docker compose logs -f
```

### 2. å•ç‹¬ç®¡ç†æœåŠ¡

```bash
# å¯åŠ¨ç‰¹å®šæœåŠ¡
docker compose up -d redis
docker compose up -d backend
docker compose up -d frontend

# æŸ¥çœ‹æ—¥å¿—
docker compose logs -f backend
docker compose logs -f frontend

# é‡å¯æœåŠ¡
docker compose restart backend

# åœæ­¢æ‰€æœ‰æœåŠ¡
docker compose down

# å®Œå…¨æ¸…ç†ï¼ˆåŒ…æ‹¬æ•°æ®å·ï¼‰
docker compose down -v
```

### 3. æ›´æ–°éƒ¨ç½²

```bash
# æ›´æ–°ä»£ç 
git pull

# é‡æ–°æ„å»ºå¹¶å¯åŠ¨
docker compose build
docker compose up -d

# æˆ–è€…ä»…æ›´æ–°ç‰¹å®šæœåŠ¡
docker compose build backend
docker compose up -d backend
```

## ğŸ“Š ç›‘æ§å’Œç»´æŠ¤

### 1. æœåŠ¡ç›‘æ§è„šæœ¬

```bash
#!/bin/bash
# docker/monitor.sh

echo "=== DockeræœåŠ¡çŠ¶æ€ ==="
docker compose ps

echo -e "\n=== å®¹å™¨èµ„æºä½¿ç”¨ ==="
docker stats --no-stream

echo -e "\n=== ç³»ç»Ÿèµ„æº ==="
echo "å†…å­˜ä½¿ç”¨:"
free -h

echo "ç£ç›˜ä½¿ç”¨:"
df -h

echo "ç³»ç»Ÿæ¸©åº¦:"
vcgencmd measure_temp 2>/dev/null || echo "æ— æ³•è¯»å–æ¸©åº¦"

echo -e "\n=== æœåŠ¡å¥åº·æ£€æŸ¥ ==="
curl -s http://localhost/health && echo "Frontend: OK" || echo "Frontend: FAIL"
curl -s http://localhost:8008/health && echo "Backend: OK" || echo "Backend: FAIL"

echo -e "\n=== æœ€è¿‘æ—¥å¿— ==="
echo "Backendé”™è¯¯æ—¥å¿—:"
docker compose logs --tail=5 backend | grep -i error

echo "å‰ç«¯è®¿é—®æ—¥å¿—:"
docker compose logs --tail=5 frontend | grep -v "/health"
```

### 2. è‡ªåŠ¨å¤‡ä»½è„šæœ¬

```bash
#!/bin/bash
# docker/backup.sh

BACKUP_DIR="/opt/chromatography/backups"
DATE=$(date +%Y%m%d_%H%M%S)

# åˆ›å»ºå¤‡ä»½ç›®å½•
mkdir -p $BACKUP_DIR

# å¤‡ä»½SQLiteæ•°æ®åº“
cp ./data/database/chromatography.db $BACKUP_DIR/db_$DATE.db

# å¤‡ä»½é…ç½®æ–‡ä»¶
tar -czf $BACKUP_DIR/config_$DATE.tar.gz .env docker/

# æ¸…ç†æ—§å¤‡ä»½ï¼ˆä¿ç•™7å¤©ï¼‰
find $BACKUP_DIR -name "*.db" -mtime +7 -delete
find $BACKUP_DIR -name "*.tar.gz" -mtime +7 -delete

echo "å¤‡ä»½å®Œæˆ: $BACKUP_DIR"
```

### 3. å®šæ—¶ä»»åŠ¡è®¾ç½®

```bash
# æ·»åŠ åˆ°crontab
crontab -e

# æ¯å¤©3ç‚¹è‡ªåŠ¨å¤‡ä»½
0 3 * * * /opt/chromatography/docker/backup.sh >> /var/log/chromatography-backup.log 2>&1

# æ¯å°æ—¶æ£€æŸ¥æœåŠ¡çŠ¶æ€
0 * * * * /opt/chromatography/docker/monitor.sh >> /var/log/chromatography-monitor.log 2>&1
```

## ğŸ”’ å®‰å…¨é…ç½®

### 1. é˜²ç«å¢™è®¾ç½®

```bash
# å®‰è£…å¹¶é…ç½®ufw
sudo apt install ufw -y

# åŸºæœ¬å®‰å…¨è§„åˆ™
sudo ufw default deny incoming
sudo ufw default allow outgoing

# å…è®¸å¿…è¦ç«¯å£
sudo ufw allow ssh
sudo ufw allow 80/tcp   # HTTP
sudo ufw allow 443/tcp  # HTTPS

# å¯ç”¨é˜²ç«å¢™
sudo ufw enable
```

### 2. Dockerå®‰å…¨é…ç½®

```yaml
# docker-compose.override.yml (ç”Ÿäº§ç¯å¢ƒ)
version: '3.8'

services:
  backend:
    # é™åˆ¶å®¹å™¨æƒé™
    cap_drop:
      - ALL
    cap_add:
      - DAC_OVERRIDE  # è®¿é—®è®¾å¤‡æ–‡ä»¶
    # åªè¯»æ ¹æ–‡ä»¶ç³»ç»Ÿ
    read_only: true
    tmpfs:
      - /tmp
      - /app/logs
    # èµ„æºé™åˆ¶
    deploy:
      resources:
        limits:
          memory: 512M
          cpus: '1.0'

  frontend:
    read_only: true
    tmpfs:
      - /tmp
      - /var/cache/nginx
      - /var/run
    deploy:
      resources:
        limits:
          memory: 128M
          cpus: '0.5'
```

## ğŸ› æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜è§£å†³

#### 1. å®¹å™¨å¯åŠ¨å¤±è´¥

```bash
# æŸ¥çœ‹è¯¦ç»†é”™è¯¯æ—¥å¿—
docker compose logs backend
docker compose logs frontend

# æ£€æŸ¥ç«¯å£å ç”¨
sudo netstat -tlnp | grep -E ':(80|8008|5432|6379)'

# æ£€æŸ¥ç£ç›˜ç©ºé—´
df -h

# æ£€æŸ¥å†…å­˜ä½¿ç”¨
free -h
```

#### 2. ä¸²å£è®¾å¤‡è®¿é—®å¤±è´¥

```bash
# æ£€æŸ¥è®¾å¤‡æ–‡ä»¶æƒé™
ls -l /dev/ttyAMA*

# æ£€æŸ¥ç”¨æˆ·ç»„æƒé™
groups $USER

# æ·»åŠ ç”¨æˆ·åˆ°dialoutç»„
sudo usermod -aG dialout $USER

# é‡æ–°å¯åŠ¨åç«¯å®¹å™¨
docker compose restart backend
```

#### 3. æ•°æ®åº“è¿æ¥é—®é¢˜

```bash
# æ£€æŸ¥SQLiteæ•°æ®åº“æ–‡ä»¶
ls -la ./data/database/chromatography.db

# è¿æ¥æ•°æ®åº“æµ‹è¯•
docker compose exec backend python -c "
import sqlite3
conn = sqlite3.connect('/app/data/chromatography.db')
cursor = conn.cursor()
cursor.execute('SELECT COUNT(*) FROM device_data')
print(f'è®¾å¤‡æ•°æ®è®°å½•æ•°: {cursor.fetchone()[0]}')
conn.close()
print('SQLiteæ•°æ®åº“è¿æ¥æ­£å¸¸')
"

# æŸ¥çœ‹æ•°æ®åº“è¡¨ç»“æ„
docker compose exec backend python -c "
import sqlite3
conn = sqlite3.connect('/app/data/chromatography.db')
cursor = conn.cursor()
cursor.execute('SELECT name FROM sqlite_master WHERE type=\\"table\\"')
tables = cursor.fetchall()
print('æ•°æ®åº“è¡¨:', [table[0] for table in tables])
conn.close()
"
```

#### 4. ç½‘ç»œè¿æ¥é—®é¢˜

```bash
# æ£€æŸ¥å®¹å™¨ç½‘ç»œ
docker network ls
docker network inspect chromatography-network

# æµ‹è¯•å®¹å™¨é—´è¿é€šæ€§
docker compose exec backend ping redis
docker compose exec frontend ping backend

# æ£€æŸ¥MQTTè¿æ¥
docker compose exec backend python -c "
import paho.mqtt.client as mqtt
client = mqtt.Client()
client.connect('broker.emqx.io', 1883, 60)
print('MQTTè¿æ¥æˆåŠŸ')
"
```

## ğŸ“ˆ æ€§èƒ½ä¼˜åŒ–

### 1. èµ„æºé…ç½®ä¼˜åŒ–

```yaml
# docker-compose.prod.yml
version: '3.8'

services:
  backend:
    environment:
      - SQLITE_JOURNAL_MODE=WAL  # æå‡å¹¶å‘æ€§èƒ½
      - SQLITE_SYNCHRONOUS=NORMAL  # å¹³è¡¡æ€§èƒ½å’Œå®‰å…¨æ€§
      - SQLITE_CACHE_SIZE=-64000  # 64MBç¼“å­˜
      - SQLITE_TEMP_STORE=memory  # ä¸´æ—¶è¡¨å­˜å‚¨åœ¨å†…å­˜

  redis:
    command: redis-server --maxmemory 128mb --maxmemory-policy allkeys-lru

  backend:
    environment:
      - WORKERS=2
      - MAX_CONNECTIONS=100
    deploy:
      resources:
        limits:
          memory: 512M
          cpus: '1.0'
        reservations:
          memory: 256M
          cpus: '0.5'
```

### 2. ç›‘æ§æŒ‡æ ‡

```bash
# ç³»ç»Ÿæ€§èƒ½ç›‘æ§
#!/bin/bash
echo "=== æ€§èƒ½æŒ‡æ ‡ ==="
echo "CPUä½¿ç”¨ç‡:"
top -bn1 | grep "Cpu(s)" | awk '{print $2}' | sed 's/%us,//'

echo "å†…å­˜ä½¿ç”¨:"
free | grep Mem | awk '{printf "ä½¿ç”¨: %.1f%% (%s/%s)\n", $3/$2 * 100.0, $3, $2}'

echo "ç£ç›˜IO:"
iostat -x 1 1 | grep -A1 mmcblk

echo "ç½‘ç»œæµé‡:"
cat /proc/net/dev | grep eth0

echo "Dockerå®¹å™¨èµ„æº:"
docker stats --no-stream --format "table {{.Container}}\t{{.CPUPerc}}\t{{.MemUsage}}\t{{.MemPerc}}"
```

## âœ… éƒ¨ç½²æ£€æŸ¥æ¸…å•

### éƒ¨ç½²å‰æ£€æŸ¥
- [ ] æ ‘è“æ´¾ç¡¬ä»¶è§„æ ¼ç¡®è®¤ (æ¨è4GB+ RAM)
- [ ] SDå¡ç©ºé—´å……è¶³ (æ¨è64GB+)
- [ ] ç½‘ç»œè¿æ¥æ­£å¸¸
- [ ] ä¸²å£è®¾å¤‡è¿æ¥æ­£ç¡® (/dev/ttyAMA*)
- [ ] Dockerç¯å¢ƒå®‰è£…å®Œæˆ

### éƒ¨ç½²è¿‡ç¨‹æ£€æŸ¥
- [ ] ä»£ç å…‹éš†/ä¸Šä¼ å®Œæˆ
- [ ] ç¯å¢ƒå˜é‡æ–‡ä»¶é…ç½® (.env)
- [ ] Dockeré•œåƒæ„å»ºæˆåŠŸ
- [ ] æ‰€æœ‰å®¹å™¨å¯åŠ¨æ­£å¸¸
- [ ] æ•°æ®åº“åˆå§‹åŒ–å®Œæˆ
- [ ] å¥åº·æ£€æŸ¥é€šè¿‡

### åŠŸèƒ½æµ‹è¯•æ£€æŸ¥
- [ ] Webç•Œé¢è®¿é—®æ­£å¸¸ (http://æ ‘è“æ´¾IP)
- [ ] APIæ¥å£å“åº”æ­£å¸¸ (/api/docs)
- [ ] MQTTè¿æ¥å’Œæ•°æ®æ¥æ”¶æ­£å¸¸
- [ ] ä¸²å£è®¾å¤‡é€šä¿¡æ­£å¸¸
- [ ] ç½‘ç»œè®¾å¤‡æ§åˆ¶æ­£å¸¸
- [ ] æ•°æ®é‡‡é›†å’Œå›¾è¡¨æ˜¾ç¤ºæ­£å¸¸

## ğŸ¯ é¢„æœŸæ€§èƒ½æŒ‡æ ‡

### ç³»ç»Ÿæ€§èƒ½
- **å¯åŠ¨æ—¶é—´**: <45ç§’ (é¦–æ¬¡æ„å»º), <10ç§’ (åç»­å¯åŠ¨)
- **å†…å­˜ä½¿ç”¨**: ~800MB (æ‰€æœ‰å®¹å™¨ï¼Œæ— PostgreSQL)
- **CPUä½¿ç”¨**: <15% (æ­£å¸¸è¿è¡Œ)
- **å­˜å‚¨ç©ºé—´**: ~1.5GB (åŒ…å«æ•°æ®å’Œæ—¥å¿—ï¼ŒSQLiteæ›´è½»é‡)

### åº”ç”¨æ€§èƒ½
- **Webå“åº”æ—¶é—´**: <200ms
- **APIå“åº”æ—¶é—´**: <100ms
- **MQTTæ¶ˆæ¯å»¶è¿Ÿ**: <50ms
- **SQLiteæŸ¥è¯¢**: <10ms (æœ¬åœ°æ–‡ä»¶ï¼Œæ›´å¿«)
- **ä¸²å£é€šä¿¡**: <100ms

## ğŸ“ æŠ€æœ¯æ”¯æŒ

### ç»´æŠ¤å»ºè®®
1. **å®šæœŸæ›´æ–°**: æ¯æœˆæ›´æ–°Dockeré•œåƒ
2. **æ•°æ®å¤‡ä»½**: æ¯å¤©è‡ªåŠ¨å¤‡ä»½æ•°æ®åº“
3. **æ—¥å¿—ç®¡ç†**: é…ç½®æ—¥å¿—è½®è½¬ï¼Œé¿å…ç£ç›˜å æ»¡
4. **æ€§èƒ½ç›‘æ§**: è®¾ç½®å‘Šè­¦é˜ˆå€¼
5. **å®‰å…¨æ›´æ–°**: åŠæ—¶æ›´æ–°åŸºç¡€é•œåƒ

### è”ç³»æ–¹å¼
- **ç³»ç»Ÿæ—¥å¿—**: `docker compose logs -f`
- **ç›‘æ§è„šæœ¬**: `/opt/chromatography/docker/monitor.sh`
- **å¤‡ä»½è„šæœ¬**: `/opt/chromatography/docker/backup.sh`

---

## ğŸ‰ éƒ¨ç½²æˆåŠŸ

éƒ¨ç½²å®Œæˆåï¼Œæ‚¨å¯ä»¥é€šè¿‡ä»¥ä¸‹æ–¹å¼è®¿é—®ç³»ç»Ÿï¼š

- **Webç•Œé¢**: http://æ ‘è“æ´¾IPåœ°å€
- **APIæ–‡æ¡£**: http://æ ‘è“æ´¾IPåœ°å€:8008/docs
- **ç³»ç»Ÿç›‘æ§**: `docker compose ps`

**SQLiteä¼˜åŠ¿æ€»ç»“:**
- âœ… é›¶é…ç½®æ•°æ®åº“ï¼šæ— éœ€ç”¨æˆ·åå¯†ç ï¼Œè‡ªåŠ¨åˆ›å»º
- âœ… è½»é‡çº§ï¼šæ— éœ€ç‹¬ç«‹æ•°æ®åº“å®¹å™¨ï¼ŒèŠ‚çœèµ„æº
- âœ… é«˜æ€§èƒ½ï¼šæœ¬åœ°æ–‡ä»¶è®¿é—®ï¼ŒæŸ¥è¯¢æ›´å¿«
- âœ… ç®€å•å¤‡ä»½ï¼šç›´æ¥å¤åˆ¶.dbæ–‡ä»¶å³å¯
- âœ… é€‚åˆåµŒå…¥å¼ï¼šå®Œç¾é€‚é…æ ‘è“æ´¾ç­‰å°å‹è®¾å¤‡

**éƒ¨ç½²ä¼˜åŠ¿æ€»ç»“:**
- âœ… é›¶æ±¡æŸ“éƒ¨ç½²ï¼šé™¤Dockerå¤–æ— éœ€ä¿®æ”¹ç³»ç»Ÿ
- âœ… ä¸€é”®å¯åŠ¨ï¼š`docker compose up -d`
- âœ… æ˜“äºç»´æŠ¤ï¼šå®¹å™¨åŒ–ç®¡ç†
- âœ… èµ„æºéš”ç¦»ï¼šå„æœåŠ¡ç‹¬ç«‹è¿è¡Œ
- âœ… é«˜å¯ç”¨æ€§ï¼šè‡ªåŠ¨é‡å¯å’Œå¥åº·æ£€æŸ¥
- âœ… æ›´è½»é‡ï¼šSQLiteå‡å°‘å†…å­˜å’Œå­˜å‚¨å ç”¨